"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __asyncValues = (this && this.__asyncValues) || function (o) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var m = o[Symbol.asyncIterator], i;
    return m ? m.call(o) : (o = typeof __values === "function" ? __values(o) : o[Symbol.iterator](), i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function () { return this; }, i);
    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }
    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.getResponsesInputMessagesAttributes = getResponsesInputMessagesAttributes;
exports.getResponsesUsageAttributes = getResponsesUsageAttributes;
exports.getResponsesOutputMessagesAttributes = getResponsesOutputMessagesAttributes;
exports.consumeResponseStreamEvents = consumeResponseStreamEvents;
const openinference_core_1 = require("@arizeai/openinference-core");
const openinference_semantic_conventions_1 = require("@arizeai/openinference-semantic-conventions");
/**
 * Get attributes for responses api Items that are not typical messages with role
 * @param item - The item to get attributes for
 * @param prefix - The prefix to use for the attributes
 * @returns The attributes for the item
 */
function getResponseItemAttributes(item, prefix = "") {
    const attributes = {};
    // all items that are not typical messages with role
    // things like images, files, etc.
    const toolCallPrefix = `${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_TOOL_CALLS}.0.`;
    switch (item.type) {
        case "function_call": {
            attributes[`${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_ROLE}`] = "assistant";
            // now using tool call prefix to simulate multiple tool calls per message
            attributes[`${toolCallPrefix}${openinference_semantic_conventions_1.SemanticConventions.TOOL_CALL_ID}`] =
                item.call_id;
            attributes[`${toolCallPrefix}${openinference_semantic_conventions_1.SemanticConventions.TOOL_CALL_FUNCTION_NAME}`] = item.name;
            attributes[`${toolCallPrefix}${openinference_semantic_conventions_1.SemanticConventions.TOOL_CALL_FUNCTION_ARGUMENTS_JSON}`] = item.arguments;
            break;
        }
        case "function_call_output": {
            attributes[`${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_ROLE}`] = "tool";
            attributes[`${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_TOOL_CALL_ID}`] =
                item.call_id;
            if (typeof item.output === "string") {
                attributes[`${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_CONTENT}`] =
                    item.output;
            }
            else {
                // TODO(2410): figure out how to serialize the list of tools
                attributes[`${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_CONTENT}`] =
                    (0, openinference_core_1.safelyJSONStringify)(item.output) || undefined;
            }
            break;
        }
        case "reasoning": {
            attributes[`${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_ROLE}`] = "assistant";
            item.summary.forEach((summaryItem, index) => {
                const summaryItemPrefix = `${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_CONTENTS}.${index}.`;
                if (summaryItem.type === "summary_text") {
                    attributes[`${summaryItemPrefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_CONTENT_TYPE}`] = "summary_text";
                    attributes[`${summaryItemPrefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_CONTENT_TEXT}`] = summaryItem.text;
                }
            });
            break;
        }
        case "item_reference": {
            break;
        }
        case "file_search_call": {
            if (!item.results) {
                // its a tool call
                attributes[`${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_ROLE}`] =
                    "assistant";
                // now using tool call prefix to simulate multiple tool calls per message
                attributes[`${toolCallPrefix}${openinference_semantic_conventions_1.SemanticConventions.TOOL_CALL_ID}`] =
                    item.id;
                attributes[`${toolCallPrefix}${openinference_semantic_conventions_1.SemanticConventions.TOOL_CALL_FUNCTION_NAME}`] = item.type;
                attributes[`${toolCallPrefix}${openinference_semantic_conventions_1.SemanticConventions.TOOL_CALL_FUNCTION_ARGUMENTS_JSON}`] = JSON.stringify(item.queries);
            }
            else {
                // its a tool call output
                attributes[`${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_ROLE}`] = "tool";
                attributes[`${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_TOOL_CALL_ID}`] =
                    item.id;
                attributes[`${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_CONTENT}`] =
                    JSON.stringify(item.results);
            }
            break;
        }
        case "computer_call": {
            attributes[`${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_ROLE}`] = "assistant";
            // now using tool call prefix to simulate multiple tool calls per message
            attributes[`${toolCallPrefix}${openinference_semantic_conventions_1.SemanticConventions.TOOL_CALL_ID}`] =
                item.id;
            attributes[`${toolCallPrefix}${openinference_semantic_conventions_1.SemanticConventions.TOOL_CALL_FUNCTION_NAME}`] = item.type;
            attributes[`${toolCallPrefix}${openinference_semantic_conventions_1.SemanticConventions.TOOL_CALL_FUNCTION_ARGUMENTS_JSON}`] = JSON.stringify(item.action);
            break;
        }
        case "computer_call_output": {
            attributes[`${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_ROLE}`] = "tool";
            attributes[`${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_TOOL_CALL_ID}`] =
                item.call_id;
            attributes[`${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_CONTENT}`] =
                JSON.stringify(item.output);
            break;
        }
        case "web_search_call": {
            attributes[`${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_ROLE}`] = "assistant";
            // now using tool call prefix to simulate multiple tool calls per message
            attributes[`${toolCallPrefix}${openinference_semantic_conventions_1.SemanticConventions.TOOL_CALL_ID}`] =
                item.id;
            attributes[`${toolCallPrefix}${openinference_semantic_conventions_1.SemanticConventions.TOOL_CALL_FUNCTION_NAME}`] = item.type;
            // web search call does not share its arguments with the caller
            // it will show "undefined" in the arguments when traced
            break;
        }
    }
    return attributes;
}
/**
 * Get attributes for responses api Item, input or output
 * Non message items are detected and handled by {@link getResponseItemAttributes}
 * @param itemMessage - The message item to get attributes for
 * @param prefix - The prefix to use for the attributes
 * @returns The attributes for the message item
 */
function getResponseItemMessageAttributes(itemMessage, prefix = "") {
    const message = typeof itemMessage === "string"
        ? { content: itemMessage, role: "user" }
        : itemMessage;
    if (!("role" in message)) {
        return getResponseItemAttributes(message, prefix);
    }
    const role = message.role;
    const attributes = {
        [`${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_ROLE}`]: role,
    };
    // add contents from message
    if (typeof message.content === "string") {
        attributes[`${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_CONTENT}`] =
            message.content;
    }
    else if (Array.isArray(message.content)) {
        message.content.forEach((part, index) => {
            const contentsIndexPrefix = `${prefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_CONTENTS}.${index}.`;
            if (part.type === "input_text") {
                attributes[`${contentsIndexPrefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_CONTENT_TYPE}`] = "input_text";
                attributes[`${contentsIndexPrefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_CONTENT_TEXT}`] = part.text;
            }
            else if (part.type === "output_text") {
                attributes[`${contentsIndexPrefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_CONTENT_TYPE}`] = "output_text";
                attributes[`${contentsIndexPrefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_CONTENT_TEXT}`] = part.text;
            }
            else if (part.type === "input_image") {
                attributes[`${contentsIndexPrefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_CONTENT_TYPE}`] = "input_image";
                if (part.image_url) {
                    attributes[`${contentsIndexPrefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_CONTENT_IMAGE}.${openinference_semantic_conventions_1.SemanticConventions.IMAGE_URL}`] = part.image_url;
                }
            }
            else if (part.type === "input_file") {
                // TODO: Handle input file
            }
            else if (part.type === "refusal") {
                attributes[`${contentsIndexPrefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_CONTENT_TYPE}`] = "refusal";
                attributes[`${contentsIndexPrefix}${openinference_semantic_conventions_1.SemanticConventions.MESSAGE_CONTENT_TEXT}`] = part.refusal;
            }
        });
    }
    // add role based fields to attributes
    // as of now, there are no role based fields as they are handled by alternatively typed
    // items
    switch (message.role) {
        case "user": {
            break;
        }
        case "assistant": {
            break;
        }
        case "system": {
            break;
        }
        case "developer": {
            break;
        }
    }
    return attributes;
}
function getResponsesInputMessagesAttributes(body) {
    var _a;
    const attributes = {};
    const items = [];
    if (body.instructions) {
        items.push({ content: body.instructions, role: "system" });
    }
    if (typeof body.input === "string") {
        items.push({ content: body.input, role: "user" });
    }
    else {
        items.push(...((_a = body.input) !== null && _a !== void 0 ? _a : []));
    }
    items.forEach((item, index) => {
        const indexPrefix = `${openinference_semantic_conventions_1.SemanticConventions.LLM_INPUT_MESSAGES}.${index}.`;
        const itemAttributes = getResponseItemMessageAttributes(item, indexPrefix);
        Object.entries(itemAttributes).forEach(([key, value]) => {
            attributes[key] = value;
        });
    });
    return attributes;
}
function getResponsesUsageAttributes(response) {
    var _a, _b;
    if (response.usage) {
        return {
            [openinference_semantic_conventions_1.SemanticConventions.LLM_TOKEN_COUNT_COMPLETION]: response.usage.output_tokens,
            [openinference_semantic_conventions_1.SemanticConventions.LLM_TOKEN_COUNT_PROMPT]: response.usage.input_tokens,
            [openinference_semantic_conventions_1.SemanticConventions.LLM_TOKEN_COUNT_TOTAL]: response.usage.total_tokens,
            [openinference_semantic_conventions_1.SemanticConventions.LLM_TOKEN_COUNT_PROMPT_DETAILS_CACHE_READ]: (_a = response.usage.input_tokens_details) === null || _a === void 0 ? void 0 : _a.cached_tokens,
            [openinference_semantic_conventions_1.SemanticConventions.LLM_TOKEN_COUNT_COMPLETION_DETAILS_REASONING]: (_b = response.usage.output_tokens_details) === null || _b === void 0 ? void 0 : _b.reasoning_tokens,
            // no audio tokens for response inputs or outputs
        };
    }
    return {};
}
function getResponsesOutputMessagesAttributes(response) {
    const attributes = {};
    const items = response.output;
    items.forEach((item, index) => {
        const indexPrefix = `${openinference_semantic_conventions_1.SemanticConventions.LLM_OUTPUT_MESSAGES}.${index}.`;
        const itemAttributes = getResponseItemMessageAttributes(item, indexPrefix);
        Object.entries(itemAttributes).forEach(([key, value]) => {
            attributes[key] = value;
        });
    });
    return attributes;
}
function consumeResponseStreamEvents(stream) {
    return __awaiter(this, void 0, void 0, function* () {
        var _a, stream_1, stream_1_1;
        var _b, e_1, _c, _d;
        let response;
        try {
            for (_a = true, stream_1 = __asyncValues(stream); stream_1_1 = yield stream_1.next(), _b = stream_1_1.done, !_b; _a = true) {
                _d = stream_1_1.value;
                _a = false;
                const event = _d;
                switch (event.type) {
                    case "response.completed": {
                        response = event.response;
                        break;
                    }
                }
            }
        }
        catch (e_1_1) { e_1 = { error: e_1_1 }; }
        finally {
            try {
                if (!_a && !_b && (_c = stream_1.return)) yield _c.call(stream_1);
            }
            finally { if (e_1) throw e_1.error; }
        }
        return response;
    });
}
//# sourceMappingURL=responsesAttributes.js.map